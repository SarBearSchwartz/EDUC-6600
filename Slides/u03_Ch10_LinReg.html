<!DOCTYPE html>
<html>
  <head>
    <title>Linear Regression</title>
    <meta charset="utf-8">
    <link rel="stylesheet" href="pres3.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Linear Regression
## Cohen Chapter 10 <br><br> .small[EDUC/PSY 6600]

---




class: center, middle

## Fit the analysis to the data, *not* the data to the analysis.

### - Statistical Maxim

---
## Motivating Example

.large[
- Dr. Ramsey conducts a *non-experimental* study to evaluate what she refers to as the 'strength-injury hypothesis.' It states that overall body strength in elderly women determines the number and severity of accidents that cause bodily injury. If the results support her hypothesis, she plans to conduct an experimental study to assess whether weight training reduces injuries in elderly women. 
- Data from 100 women who range in age from 60 to 70 years old are collected. The women initially undergo a series of measures that assess upper and lower body strength, and these measures are summarized into an overall index of body strength. 
- Over the next 5 years, the women record each time they have an accident that results in a bodily injury and describe fully the extent of the injury. On the basis of these data, Dr. Ramsey calculates an overall injury index for each woman. 
- A simple regression analysis is conducted with the overall index of body strength as the predictor (independent) variable and the overall injury index as the outcome (dependent) variable. 

]

---
# Correlation vs. Regression

.pull-left[
## Correlation
.large[
- Relationship between two variables (no outcome or predictor)
- Strength and direction of relationship
]]

--

.pull-right[
## Regression
.large[
- Outcome and predictor (directional)
- Simple and Multiple Linear Regression
]]

---
# Regression Basics

.pull-left[.large[
- Y usually predicted variable
  - A.k.a: Dependent, criterion, outcome, response variable
  - Predicting Y from X = 'Regressing Y on X'
- X usually variable used to predict Y
  - A.k.a: Independent, predictor, explanatory variable
- Different results when X &amp; Y switched
]]

.pull-right[.large[
Regression analysis is procedure for obtaining *the* line that best fits data (Assuming relationship is best described as linear)
]]

---
# Regression Basics

$$ \LARGE \hat{Y_i} = b_0 + b_1 X_i $$

.pull-left[.large[

.dcoral[
`\(\Large \hat{Y_i}\)` = predicted (unobserved) value of Y for a given case i
]

.bluer[
`\(\Large b_0\)` = y-intercept:

Constant, `\(\Large \hat{Y}\)` when X = 0, only interpreted if X = 0 is meaningful

Alternative notation: `\(\Large a\)` or `\(\Large a_{XY}\)` 

]]]

.pull-right[.large[
.nicegreen[
`\(\Large b_1\)` = slope of regression line for 1st IV

Constant, Rate of change in Y for every 1-unit change in X

Alternative notation: `\(\Large b_{XY}\)`
]

.dcoral[
`\(\Large X_i\)` = value of predictor for a given case i
]]]

---
# Accuracy of Prediction
.huge[
.dcoral[Correlation] `\(\Large \neq\)` .dcoral[Causation]
]

.large[

- All points do not fall on regression line
  - Prediction works for most, but not all in sample

- W/out knowledge of X, best prediction of Y is mean `\(\Large \bar{Y}\)`
  - Y: best measure of prediction error

- With knowledge of X, best prediction of Y is from the equation `\(\Large \hat{Y}\)`
  - Standard error of estimate (SEE or `\(s_{Y.X}\)` ): best measure of prediction error
  - Estimated SD of residuals in population
]

---
background-image: url(figures/fig_spurious.jpeg)
background-position: 50% 50%
background-size: 1200px


.footnote[http://www.tylervigen.com/spurious-correlations]

---
# Always **Visualize** Data First

### Scatterplots



.pull-left[

*Aka: scatterdiagrams, scattergrams*

Notes:
1. Can stratify scatterplots by subgroups
2. Each subject is represented by 1 dot (x and y coordinate)
3. Fit line can indicate nature and degree of relationship (Regression or prediction lines)



```r
library(tidyverse)
df %&gt;%
  ggplot(aes(x, y)) +
    geom_point() +
    geom_smooth(se = FALSE,
                method = "lm")
```
]

.pull-right[
&lt;img src="u03_Ch10_LinReg_files/figure-html/unnamed-chunk-3-1.png" style="display: block; margin: auto;" /&gt;
]

---





---





---
class: inverse, center, middle

# Let's Apply This to the Cancer Dataset 


---
# Read in the Data


```r
library(tidyverse)    # Loads several very helpful 'tidy' packages
library(haven)        # Read in SPSS datasets
library(furniture)    # for tableC()
```


```r
cancer_raw &lt;- haven::read_spss("cancer.sav")
```



### And Clean It


```r
cancer_clean &lt;- cancer_raw %&gt;% 
  dplyr::rename_all(tolower) %&gt;% 
  dplyr::mutate(id = factor(id)) %&gt;% 
  dplyr::mutate(trt = factor(trt,
                             labels = c("Placebo", 
                                        "Aloe Juice"))) %&gt;% 
  dplyr::mutate(stage = factor(stage))
```

---
# R Code: Basic Correlations

.pull-left[

```r
cancer_clean %&gt;%
  cor.test(~ totalcin + totalcw2,
           data = .,
           alternative = "two.sided",
           method = "pearson")
```

]

.pull-right[

```

	Pearson's product-moment correlation

data:  totalcin and totalcw2
t = 1.5885, df = 23, p-value = 0.1258
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 -0.09215959  0.63114058
sample estimates:
     cor 
0.314421 
```
]
---
count: false

# R Code: Basic Correlations

.pull-left[

```r
cancer_clean %&gt;%
  cor.test(~ totalcin + totalcw2,
           data = .,
           alternative = "two.sided",
           method = "pearson")
```


```r
cancer_clean %&gt;%
  cor.test(~ totalcin + totalcw2,
           data = .,
           alternative = "less",
           method = "pearson")
```


```r
cancer_clean %&gt;%
  cor.test(~ totalcin + totalcw2,
           data = .,
           alternative = "greater",
           method = "pearson")
```
]

.pull-right[

```

	Pearson's product-moment correlation

data:  totalcin and totalcw2
t = 1.5885, df = 23, p-value = 0.1258
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 -0.09215959  0.63114058
sample estimates:
     cor 
0.314421 
```
]

---
## R Code: Correlation Matrix

.pull-left[

```r
cancer_clean %&gt;%
  furniture::tableC(totalcin, totalcw2, 
                    totalcw4, totalcw6)
```
]

.pull-right[

```r
cancer_clean %&gt;%
  furniture::tableC(totalcin, totalcw2, 
                    totalcw4, totalcw6,
                    na.rm=TRUE)
```
]

```

─────────────────────────────────────────────────────
             [1]           [2]           [3]   [4]  
 [1]totalcin 1.00                                   
 [2]totalcw2 0.314 (0.126) 1.00                     
 [3]totalcw4 0.222 (0.287) 0.337 (0.099) 1.00       
 [4]totalcw6 NA NA         NA NA         NA NA 1.00 
─────────────────────────────────────────────────────
```

```

─────────────────────────────────────────────────────────────
             [1]           [2]           [3]           [4]  
 [1]totalcin 1.00                                           
 [2]totalcw2 0.282 (0.192) 1.00                             
 [3]totalcw4 0.206 (0.346) 0.314 (0.145) 1.00               
 [4]totalcw6 0.098 (0.657) 0.378 (0.075) 0.763 (&lt;.001) 1.00 
─────────────────────────────────────────────────────────────
```


---
# R Code: Scatterplot with Regression Line


```r
cancer_clean %&gt;%
  ggplot(aes(totalcin, totalcw2)) +
    geom_point() +
    geom_smooth(method = "lm")
```

&lt;img src="u03_Ch10_LinReg_files/figure-html/unnamed-chunk-18-1.png" style="display: block; margin: auto;" /&gt;



---
# R Code: Scatterplot with Count


```r
cancer_clean %&gt;%
  ggplot(aes(totalcin, totalcw2)) +
    geom_count() +
    geom_smooth(method = "lm")
```

&lt;img src="u03_Ch10_LinReg_files/figure-html/unnamed-chunk-19-1.png" style="display: block; margin: auto;" /&gt;



---
class: inverse, center, middle

# Questions?


---
class: inverse, center, middle

# Next Topic

### Linear Regression
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {window.dispatchEvent(new Event('resize'));});
(function() {var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler"); if (!r) return; s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }"; d.head.appendChild(s);})();</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
});
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
